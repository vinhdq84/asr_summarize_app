{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from models/llama2/llama-2-13b-chat.ggmlv3.q4_K_M.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 512\n",
      "llama_model_load_internal: n_embd     = 5120\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 40\n",
      "llama_model_load_internal: n_layer    = 40\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: freq_base  = 10000.0\n",
      "llama_model_load_internal: freq_scale = 1\n",
      "llama_model_load_internal: ftype      = 15 (mostly Q4_K - Medium)\n",
      "llama_model_load_internal: n_ff       = 13824\n",
      "llama_model_load_internal: model size = 13B\n",
      "llama_model_load_internal: ggml ctx size =    0.09 MB\n",
      "llama_model_load_internal: mem required  = 9336.95 MB (+ 1608.00 MB per state)\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n",
      "llama_new_context_with_model: kv self size  =  400.00 MB\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "llm = Llama(\n",
    "    model_path=\"models/llama2/llama-2-13b-chat.ggmlv3.q4_K_M.bin\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_to_sum = \"This man is so fast. Once upon a time I saw him running around in flash time. One day, I found him dead.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "This\n",
      " man\n",
      " was\n",
      " incred\n",
      "ibly\n",
      " fast\n",
      " and\n",
      " could\n",
      " run\n",
      " at\n",
      " an\n",
      " aston\n",
      "ishing\n",
      " speed\n",
      ",\n",
      " almost\n",
      " like\n",
      " he\n",
      " was\n",
      " moving\n",
      " in\n",
      " flash\n",
      " time\n",
      ".\n",
      " Unfortunately\n",
      ",\n",
      " one\n",
      " day\n",
      " he\n",
      " was\n",
      " found\n",
      " dead\n",
      ".\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time = 26292.03 ms\n",
      "llama_print_timings:      sample time =    14.96 ms /    35 runs   (    0.43 ms per token,  2339.10 tokens per second)\n",
      "llama_print_timings: prompt eval time = 26291.91 ms /    50 tokens (  525.84 ms per token,     1.90 tokens per second)\n",
      "llama_print_timings:        eval time = 21381.21 ms /    34 runs   (  628.86 ms per token,     1.59 tokens per second)\n",
      "llama_print_timings:       total time = 47760.94 ms\n"
     ]
    }
   ],
   "source": [
    "for i in llm(\n",
    "    prompt=f\"### Instruction: Summarize the following, return the summarized text only: {content_to_sum}\\n### Response:\",\n",
    "    stream=True,\n",
    "):\n",
    "    print(i[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "whisper_init_from_file_no_state: loading model from '/home/vinhdq/matrix/ASR_and_Summarize/asr_summarize_app/models/whisper/ggml-tiny.en.bin'\n",
      "whisper_model_load: loading model\n",
      "whisper_model_load: n_vocab       = 51864\n",
      "whisper_model_load: n_audio_ctx   = 1500\n",
      "whisper_model_load: n_audio_state = 384\n",
      "whisper_model_load: n_audio_head  = 6\n",
      "whisper_model_load: n_audio_layer = 4\n",
      "whisper_model_load: n_text_ctx    = 448\n",
      "whisper_model_load: n_text_state  = 384\n",
      "whisper_model_load: n_text_head   = 6\n",
      "whisper_model_load: n_text_layer  = 4\n",
      "whisper_model_load: n_mels        = 80\n",
      "whisper_model_load: f16           = 1\n",
      "whisper_model_load: type          = 1\n",
      "whisper_model_load: mem required  =  129.00 MB (+    3.00 MB per decoder)\n",
      "whisper_model_load: adding 1607 extra tokens\n",
      "whisper_model_load: model ctx     =   73.58 MB\n",
      "whisper_model_load: model size    =   73.54 MB\n",
      "whisper_init_state: kv self size  =    2.62 MB\n",
      "whisper_init_state: kv cross size =    8.79 MB\n"
     ]
    }
   ],
   "source": [
    "from whispercpp import Whisper\n",
    "\n",
    "w = Whisper.from_pretrained(\n",
    "    \"/home/vinhdq/matrix/ASR_and_Summarize/asr_summarize_app/models/whisper/ggml-tiny.en.bin\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" It wasn't like I was asking for the code to uniquely a bunker or anything like that, but the amount of resistance I got from this\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ffmpeg\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    y, _ = (\n",
    "        ffmpeg.input(\n",
    "            \"/home/vinhdq/matrix/ASR_and_Summarize/whisper.cpp/samples/sample1.wav\",\n",
    "            threads=0,\n",
    "        )\n",
    "        .output(\"-\", format=\"s16le\", acodec=\"pcm_s16le\", ac=1, ar=16000)\n",
    "        .run(cmd=[\"ffmpeg\", \"-nostdin\"], capture_stdout=True, capture_stderr=True)\n",
    "    )\n",
    "except ffmpeg.Error as e:\n",
    "    raise RuntimeError(f\"Failed to load audio: {e.stderr.decode()}\") from e\n",
    "\n",
    "arr = np.frombuffer(y, np.int16).flatten().astype(np.float32) / 32768.0\n",
    "\n",
    "w.transcribe(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "init_device: Using device: '(null)' ...\n",
      "\n",
      "Opened audio device: (id=2, name=(null))\n",
      "  - sample_rate: 16000\n",
      "  - format: 33056 (required: 33056)\n",
      "  - channels: 1 (required: 1)\n",
      "  - samples per frame: 1024\n",
      "\n",
      "\n",
      "stream_transcribe: processing 40000 samples (step = 2.5 sec / len = 5.0 sec / keep = 0.2 sec), 8 threads, lang = en, task = transcribe, timestamps = 0 ...\n",
      "stream_transcribe: n_new_line = 1, no_context = 1\n",
      "\n",
      "=====================================\n",
      "=== Transcription starting now... ===\n",
      "=====================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from io import StringIO\n",
    "import sys\n",
    "\n",
    "capture = StringIO()\n",
    "sys.stdout = capture\n",
    "\n",
    "w.stream_transcribe(5000, sample_rate=16000, step_ms=2500, n_threads=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment: get audio from microphone & transcribe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_route.c:869:(find_matching_chmap) Found no matching channel map\n",
      "ALSA lib pcm_oss.c:377:(_snd_pcm_oss_open) Unknown field port\n",
      "ALSA lib pcm_oss.c:377:(_snd_pcm_oss_open) Unknown field port\n",
      "ALSA lib pcm_usb_stream.c:486:(_snd_pcm_usb_stream_open) Invalid type for card\n",
      "ALSA lib pcm_usb_stream.c:486:(_snd_pcm_usb_stream_open) Invalid type for card\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def process_audio(in_data, frame_count, time_info, status_flags):\n",
    "    audio_data = np.frombuffer(in_data, dtype=np.float32)\n",
    "\n",
    "    print(audio_data.shape)\n",
    "\n",
    "    return (in_data, pyaudio.paContinue)\n",
    "\n",
    "\n",
    "# Set up PyAudio\n",
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "sr = 16000\n",
    "sample_format = pyaudio.paFloat32\n",
    "chunk = 1024\n",
    "time_to_record = 3\n",
    "\n",
    "stream = audio.open(\n",
    "    format=sample_format,\n",
    "    channels=1,\n",
    "    rate=sr,\n",
    "    input=True,\n",
    "    output=False,\n",
    "    frames_per_buffer=chunk,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.90625"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr / chunk * 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "while True:\n",
    "    data = data[-int(sr * 0.25) // (chunk) :]\n",
    "    for _ in range(sr // chunk * time_to_record):\n",
    "        data.append(stream.read(chunk))\n",
    "    print(w.transcribe(np.frombuffer(b\"\".join(data), dtype=np.float32)))\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "\n",
    "file = wave.open(\"sample.wav\", \"wb\")\n",
    "file.setnchannels(1)\n",
    "file.setsampwidth(audio.get_sample_size(sample_format))\n",
    "file.setframerate(sr)\n",
    "\n",
    "# Write and Close the File\n",
    "file.writeframes(b\"\".join(data))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "adu = np.frombuffer(b\"\".join(data), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Sometimes I'm scared\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.transcribe(adu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
